{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PM_china.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAbbottPersonal/PM_china/blob/main/PM_china.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YHJjnD_Tja"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxyV4R5dfySU"
      },
      "source": [
        "There are several PM reading for each dataset. Store all of them as a dictionary of numpy arrays for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrxyEKGn_ez7"
      },
      "source": [
        "dataset = pd.read_csv('/content/BeijingPM20100101_20151231.csv')\n",
        "#X = dataset.iloc[:, :-1].values\n",
        "features = ['No', \n",
        "            'year', \n",
        "            'month', \n",
        "            'day', \n",
        "            'hour', \n",
        "            'season', \n",
        "            'DEWP', \n",
        "            'HUMI',\n",
        "            'PRES', \n",
        "            'TEMP', \n",
        "            'cbwd', \n",
        "            'Iws', \n",
        "            'precipitation', \n",
        "            'Iprec']\n",
        "X = dataset.loc[:, features].values\n",
        "y = {}\n",
        "for i in dataset.columns:\n",
        "  if 'PM_' in i:\n",
        "    y[i] = dataset.loc[:, i].values"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKpOrig6ddZC",
        "outputId": "5524bcd8-b01e-43ad-9707-6235b3896d56"
      },
      "source": [
        "print(type(X))\n",
        "print(X[0:4,:])\n",
        "print(y)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2010 1 1 0 4 -21.0 43.0 1021.0 -11.0 'NW' 1.79 0.0 0.0]\n",
            " [2 2010 1 1 1 4 -21.0 47.0 1020.0 -12.0 'NW' 4.92 0.0 0.0]\n",
            " [3 2010 1 1 2 4 -21.0 43.0 1019.0 -11.0 'NW' 6.71 0.0 0.0]\n",
            " [4 2010 1 1 3 4 -21.0 55.0 1019.0 -14.0 'NW' 9.84 0.0 0.0]]\n",
            "{'PM_Dongsi': array([ nan,  nan,  nan, ..., 171., 204.,  nan]), 'PM_Dongsihuan': array([ nan,  nan,  nan, ..., 231., 242.,  nan]), 'PM_Nongzhanguan': array([ nan,  nan,  nan, ..., 196., 221.,  nan]), 'PM_US Post': array([ nan,  nan,  nan, ..., 203., 212., 235.])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BpLQI8kaf_3"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pFRLeMdaz8R"
      },
      "source": [
        "### Imputing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOzC-L6Za2bl"
      },
      "source": [
        "I need to remove the NA values and handle large periods of time without any PM data from the other chinese locations. The general strategy is:\n",
        "\n",
        "\n",
        "1.   Impute the NA values of the US Post. These values are for the most part ubiquitous in the dataset with execption for of a few days.\n",
        "2.   Do not impute the other locations. If they are available, average them together (with the US post and other chinese locations).\n",
        "3.   Use the average as the final PM value.\n",
        "\n",
        "I am also considering MTR (multi-target regression) but for now just use step 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WenhZuZgb_vn"
      },
      "source": [
        "1: Impute the US_post values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trz2DP1ocEId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00443d2a-adb7-46c0-ce5e-6293f5d9184c"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "print(y['PM_US Post'])\n",
        "US_post_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "US_post_imputer.fit(y['PM_US Post'].reshape(1,-1))\n",
        "y['PM_US Post'] = US_post_imputer.transform(y['PM_US Post'].reshape(1,-1))\n",
        "print(y['PM_US Post'][-1])\n"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ nan  nan  nan ... 203. 212. 235.]\n",
            "[129. 148. 159. ... 203. 212. 235.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5LDZCMxmyRY"
      },
      "source": [
        "2: Average locations (TO DO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLaoZnvMm1aQ"
      },
      "source": [
        ""
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Sb1QZbm1mZ"
      },
      "source": [
        "3: Store Average (TO DO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFcc7YEPpL4N"
      },
      "source": [
        ""
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xses2bkhpM2D"
      },
      "source": [
        "There are some values that need imputing in the feature set.\n",
        "*    Precipitiation (Precipitation and lprec): Use median as mean could produce odd or tiny values of precipitaion.\n",
        "*    Wind direction (cbwd): Use local average of neighbors (p/m 2 rows) since we don't expect the wind direction to change suddenly (or at least that is my intuition!). This is categorical and will have to be encoded before manipulation.\n",
        "*    Other values with NAA (DEWP, HUMI, PRES, TEMP, LWS): Use local average of neighbors for this as well but unlike wind direction this is numerical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4RAs8N0ubf3"
      },
      "source": [
        "Precipitation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I6nDDMKunpx",
        "outputId": "bcb0cb02-f869-4fd8-df30-24b689e05979"
      },
      "source": [
        "#print(X[42898:42903,-2:])\n",
        "print(\"Before and after imputing: \")\n",
        "print(np.count_nonzero(np.isnan(X[:,-2:].astype(np.float))))\n",
        "prec_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "prec_imputer.fit(X[:,-2:])\n",
        "X[:,-2:] = prec_imputer.transform(X[:,-2:])\n",
        "print(np.count_nonzero(np.isnan(X[:,-2:].astype(np.float))))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before and after imputing: \n",
            "968\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0OwopfV3xv2"
      },
      "source": [
        "Other features (not wind direction):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6EYOVcnFrUr",
        "outputId": "a4604f14-f3cd-4c00-fbed-4d640e893586"
      },
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "print(X[45920:45925,:])\n",
        "print(np.count_nonzero(np.isnan(X[:,[-8,-7,-6,-5,-3]].astype(np.float))))\n",
        "\n",
        "\n",
        "for col in [-8,-7,-6,-5,-3]:\n",
        "  df = DataFrame(data = X[:,col])\n",
        "  df = df.iloc[:, -1].astype(float).interpolate(method='linear')\n",
        "  X[:,col] = df\n",
        "\n",
        "\n",
        "print(X[45920:45925,:])\n",
        "print(np.count_nonzero(np.isnan(X[:,[-8,-7,-6,-5,-3]].astype(np.float))))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 nan nan nan nan nan nan 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "693\n",
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 4.0 44.0 1018.0 16.0 nan 3.13 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiRf7w5Hx0io"
      },
      "source": [
        "Wind direction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qFFqp3mx3GN",
        "outputId": "1c419cf1-a9f7-483a-f830-2b7ba79ae075"
      },
      "source": [
        "winds = X[:,-4]\n",
        "new_cols = np.zeros((len(winds),5))\n",
        "winds = np.vstack(winds)\n",
        "new_cols = np.concatenate((winds, new_cols),1)\n",
        "\n",
        "\n",
        "new_cols[new_cols[:,0] == 'NE'] = ['NE', 1., 0., 0., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'NW'] = ['NW', 0., 1., 0., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'SW'] = ['SW', 0., 0., 1., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'SE'] = ['SE', 0., 0., 0., 1., 0.]\n",
        "new_cols[new_cols[:,0] == 'cv'] = ['cv', 0., 0., 0., 0., 1.]\n",
        "new_cols[new_cols[:,0] == 'nan'] = ['nan', np.NaN, np.NaN, np.NaN, np.NaN, np.NaN]\n",
        "\n",
        "\n",
        "print(np.count_nonzero(np.isnan(new_cols[:,1].astype(np.float))))\n",
        "\n",
        "\n",
        "df = DataFrame(data = new_cols)\n",
        "df = df.iloc[:, 1:].astype(float).fillna(method='bfill')\n",
        "final = df.values\n",
        "print(np.count_nonzero(np.isnan(final[:,1].astype(np.float))))\n",
        "\n",
        "print(X[45920:45925,:])\n",
        "X = np.concatenate((X,final),1)\n",
        "print(X[21670:21680,:])"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0\n",
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 4.0 44.0 1018.0 16.0 nan 3.13 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "[[21671 2012 6 21 22 2 18.0 73.0 1005.0 23.0 'SE' 21.01 2.6 2.7 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21672 2012 6 21 23 2 19.0 88.0 1004.0 21.0 'SE' 25.03 1.1 3.8 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21673 2012 6 22 0 2 19.0 93.0 1004.0 20.0 'SE' 28.16 0.1 3.9 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21674 2012 6 22 1 2 19.0 93.0 1004.0 20.0 'SE' 33.97 0.5 4.4 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21675 2012 6 22 2 2 19.0 93.0 1004.0 20.0 'cv' 0.89 0.1 4.5 0.0 0.0 0.0\n",
            "  0.0 1.0]\n",
            " [21676 2012 6 22 3 2 20.0 100.0 1004.0 20.0 'NW' 1.79 0.0 0.0 0.0 1.0\n",
            "  0.0 0.0 0.0]\n",
            " [21677 2012 6 22 4 2 19.0 93.0 1004.0 20.0 'NW' 4.92 0.2 0.2 0.0 1.0 0.0\n",
            "  0.0 0.0]\n",
            " [21678 2012 6 22 5 2 19.0 93.0 1004.0 20.0 'SE' 0.89 0.0 0.0 0.0 0.0 0.0\n",
            "  1.0 0.0]\n",
            " [21679 2012 6 22 6 2 20.0 94.0 1004.0 21.0 'SE' 2.68 0.0 0.0 0.0 0.0 0.0\n",
            "  1.0 0.0]\n",
            " [21680 2012 6 22 7 2 20.0 88.0 1005.0 22.0 'cv' 0.89 0.0 0.0 0.0 0.0 0.0\n",
            "  0.0 1.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXtHRUb5auwQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb_v_ae-A-20"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywPjx0L1BMiD"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQKmwvtdBkyb"
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50DZZy0UyhLi"
      },
      "source": [
        "## Evaluating the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPagAOKDywV4"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}