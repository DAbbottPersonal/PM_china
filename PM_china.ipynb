{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PM_china.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAbbottPersonal/PM_china/blob/main/PM_china.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YHJjnD_Tja"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxyV4R5dfySU"
      },
      "source": [
        "There are several PM reading for each dataset. Store all of them as a dictionary of numpy arrays for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrxyEKGn_ez7"
      },
      "source": [
        "dataset = pd.read_csv('/content/BeijingPM20100101_20151231.csv')\n",
        "#X = dataset.iloc[:, :-1].values\n",
        "features = ['No', \n",
        "            'year', \n",
        "            'month', \n",
        "            'day', \n",
        "            'hour', \n",
        "            'season', \n",
        "            'DEWP', \n",
        "            'HUMI',\n",
        "            'PRES', \n",
        "            'TEMP', \n",
        "            'cbwd', \n",
        "            'Iws', \n",
        "            'precipitation', \n",
        "            'Iprec']\n",
        "X = dataset.loc[:, features].values\n",
        "y = {}\n",
        "for i in dataset.columns:\n",
        "  if 'PM_' in i:\n",
        "    y[i] = dataset.loc[:, i].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKpOrig6ddZC",
        "outputId": "6daa2e1c-65d8-4c0f-dd82-3bc6891f1541"
      },
      "source": [
        "print(type(X))\n",
        "print(X[0:4,:])\n",
        "print(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2010 1 1 0 4 -21.0 43.0 1021.0 -11.0 'NW' 1.79 0.0 0.0]\n",
            " [2 2010 1 1 1 4 -21.0 47.0 1020.0 -12.0 'NW' 4.92 0.0 0.0]\n",
            " [3 2010 1 1 2 4 -21.0 43.0 1019.0 -11.0 'NW' 6.71 0.0 0.0]\n",
            " [4 2010 1 1 3 4 -21.0 55.0 1019.0 -14.0 'NW' 9.84 0.0 0.0]]\n",
            "{'PM_Dongsi': array([ nan,  nan,  nan, ..., 171., 204.,  nan]), 'PM_Dongsihuan': array([ nan,  nan,  nan, ..., 231., 242.,  nan]), 'PM_Nongzhanguan': array([ nan,  nan,  nan, ..., 196., 221.,  nan]), 'PM_US Post': array([ nan,  nan,  nan, ..., 203., 212., 235.])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BpLQI8kaf_3"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pFRLeMdaz8R"
      },
      "source": [
        "### Imputing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOzC-L6Za2bl"
      },
      "source": [
        "I need to remove the NA values and handle large periods of time without any PM data from the other chinese locations. The general strategy is:\n",
        "\n",
        "\n",
        "1.   Impute the NA values of the US Post. These values are for the most part ubiquitous in the dataset with execption for of a few days.\n",
        "2.   Do not impute the other locations. If they are available, average them together (with the US post and other chinese locations).\n",
        "3.   Use the average as the final PM value.\n",
        "\n",
        "I am also considering MTR (multi-target regression) but for now just use step 1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WenhZuZgb_vn"
      },
      "source": [
        "1: Impute the US_post values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trz2DP1ocEId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38e2db4-b75c-41db-e320-7e7c6ed66a9e"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "print(y['PM_US Post'])\n",
        "print(len(y['PM_US Post']))\n",
        "print(np.count_nonzero(np.isnan(y['PM_US Post'].astype(np.float))))\n",
        "y_prep = np.vstack(y['PM_US Post'])\n",
        "print(y_prep)\n",
        "US_post_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "US_post_imputer.fit(y_prep)\n",
        "y['PM_US Post'] = US_post_imputer.transform(y_prep)\n",
        "print(y['PM_US Post'])\n",
        "print(len(y['PM_US Post']))\n",
        "print(np.count_nonzero(np.isnan(y['PM_US Post'].astype(np.float))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ nan  nan  nan ... 203. 212. 235.]\n",
            "52584\n",
            "2197\n",
            "[[ nan]\n",
            " [ nan]\n",
            " [ nan]\n",
            " ...\n",
            " [203.]\n",
            " [212.]\n",
            " [235.]]\n",
            "[[ 69.]\n",
            " [ 69.]\n",
            " [ 69.]\n",
            " ...\n",
            " [203.]\n",
            " [212.]\n",
            " [235.]]\n",
            "52584\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5LDZCMxmyRY"
      },
      "source": [
        "2: Average locations (TO DO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLaoZnvMm1aQ"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Sb1QZbm1mZ"
      },
      "source": [
        "3: Store Average (TO DO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFcc7YEPpL4N"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xses2bkhpM2D"
      },
      "source": [
        "There are some values that need imputing in the feature set.\n",
        "*    Precipitiation (Precipitation and lprec): Use median as mean could produce odd or tiny values of precipitaion.\n",
        "*    Wind direction (cbwd): Use local average of neighbors (p/m 2 rows) since we don't expect the wind direction to change suddenly (or at least that is my intuition!). This is categorical and will have to be encoded before manipulation.\n",
        "*    Other values with NAA (DEWP, HUMI, PRES, TEMP, LWS): Use local average of neighbors for this as well but unlike wind direction this is numerical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4RAs8N0ubf3"
      },
      "source": [
        "Precipitation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I6nDDMKunpx",
        "outputId": "d2ac6b98-0532-4dcc-febf-eb45562e8b67"
      },
      "source": [
        "#print(X[42898:42903,-2:])\n",
        "print(\"Before and after imputing: \")\n",
        "print(np.count_nonzero(np.isnan(X[:,-2:].astype(np.float))))\n",
        "prec_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "prec_imputer.fit(X[:,-2:])\n",
        "X[:,-2:] = prec_imputer.transform(X[:,-2:])\n",
        "print(np.count_nonzero(np.isnan(X[:,-2:].astype(np.float))))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before and after imputing: \n",
            "968\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0OwopfV3xv2"
      },
      "source": [
        "Other features (not wind direction):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6EYOVcnFrUr",
        "outputId": "3acf6202-a356-429a-8fa4-865ddc351f0f"
      },
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "print(X[45920:45925,:])\n",
        "print(np.count_nonzero(np.isnan(X[:,[-8,-7,-6,-5,-3]].astype(np.float))))\n",
        "\n",
        "\n",
        "for col in [-8,-7,-6,-5,-3]:\n",
        "  df = DataFrame(data = X[:,col])\n",
        "  df = df.iloc[:, -1].astype(float).interpolate(method='linear')\n",
        "  X[:,col] = df\n",
        "\n",
        "\n",
        "print(X[45920:45925,:])\n",
        "print(np.count_nonzero(np.isnan(X[:,[-8,-7,-6,-5,-3]].astype(np.float))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 nan nan nan nan nan nan 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "693\n",
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 4.0 44.0 1018.0 16.0 nan 3.13 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiRf7w5Hx0io"
      },
      "source": [
        "Wind direction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qFFqp3mx3GN",
        "outputId": "eb5f8054-5b2a-431f-d2d4-4c5a443a8e94"
      },
      "source": [
        "winds = X[:,-4]\n",
        "new_cols = np.zeros((len(winds),5))\n",
        "winds = np.vstack(winds)\n",
        "new_cols = np.concatenate((winds, new_cols),1)\n",
        "\n",
        "\n",
        "new_cols[new_cols[:,0] == 'NE'] = ['NE', 1., 0., 0., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'NW'] = ['NW', 0., 1., 0., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'SW'] = ['SW', 0., 0., 1., 0., 0.]\n",
        "new_cols[new_cols[:,0] == 'SE'] = ['SE', 0., 0., 0., 1., 0.]\n",
        "new_cols[new_cols[:,0] == 'cv'] = ['cv', 0., 0., 0., 0., 1.]\n",
        "new_cols[new_cols[:,0] == 'nan'] = ['nan', np.NaN, np.NaN, np.NaN, np.NaN, np.NaN]\n",
        "\n",
        "\n",
        "print(np.count_nonzero(np.isnan(new_cols[:,1].astype(np.float))))\n",
        "\n",
        "\n",
        "df = DataFrame(data = new_cols)\n",
        "df = df.iloc[:, 1:].astype(float).fillna(method='bfill')\n",
        "final = df.values\n",
        "print(np.count_nonzero(np.isnan(final[:,1].astype(np.float))))\n",
        "\n",
        "print(X[45920:45925,:])\n",
        "X = np.concatenate((X,final),1)\n",
        "print(X[21670:21680,:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0\n",
            "[[45921 2015 3 29 8 1 3.0 50.0 1018.0 13.0 'cv' 0.89 0.0 0.0]\n",
            " [45922 2015 3 29 9 1 4.0 47.0 1018.0 15.0 'SE' 3.13 0.0 0.0]\n",
            " [45923 2015 3 29 10 1 4.0 44.0 1018.0 16.0 nan 3.13 0.0 0.0]\n",
            " [45924 2015 3 29 11 1 4.0 41.0 1018.0 17.0 'SE' 3.13 0.0 0.0]\n",
            " [45925 2015 3 29 12 1 4.0 34.0 1015.0 20.0 'SE' 8.05 0.0 0.0]]\n",
            "[[21671 2012 6 21 22 2 18.0 73.0 1005.0 23.0 'SE' 21.01 2.6 2.7 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21672 2012 6 21 23 2 19.0 88.0 1004.0 21.0 'SE' 25.03 1.1 3.8 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21673 2012 6 22 0 2 19.0 93.0 1004.0 20.0 'SE' 28.16 0.1 3.9 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21674 2012 6 22 1 2 19.0 93.0 1004.0 20.0 'SE' 33.97 0.5 4.4 0.0 0.0\n",
            "  0.0 1.0 0.0]\n",
            " [21675 2012 6 22 2 2 19.0 93.0 1004.0 20.0 'cv' 0.89 0.1 4.5 0.0 0.0 0.0\n",
            "  0.0 1.0]\n",
            " [21676 2012 6 22 3 2 20.0 100.0 1004.0 20.0 'NW' 1.79 0.0 0.0 0.0 1.0\n",
            "  0.0 0.0 0.0]\n",
            " [21677 2012 6 22 4 2 19.0 93.0 1004.0 20.0 'NW' 4.92 0.2 0.2 0.0 1.0 0.0\n",
            "  0.0 0.0]\n",
            " [21678 2012 6 22 5 2 19.0 93.0 1004.0 20.0 'SE' 0.89 0.0 0.0 0.0 0.0 0.0\n",
            "  1.0 0.0]\n",
            " [21679 2012 6 22 6 2 20.0 94.0 1004.0 21.0 'SE' 2.68 0.0 0.0 0.0 0.0 0.0\n",
            "  1.0 0.0]\n",
            " [21680 2012 6 22 7 2 20.0 88.0 1005.0 22.0 'cv' 0.89 0.0 0.0 0.0 0.0 0.0\n",
            "  0.0 1.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSEFaRp5spI3"
      },
      "source": [
        "Last, I will clean out the variables that may not be helpful like the string value of the wind direction and event number (since this will not be useful in prediction)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDH-giZosxDY"
      },
      "source": [
        "X_final = X[:,[1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18]]\n",
        "features_final = ['year',\n",
        "                  'month',\n",
        "                  'day',\n",
        "                  'hour',\n",
        "                  'season',\n",
        "                  'DEWP',\n",
        "                  'HUMI',\n",
        "                  'PRES',\n",
        "                  'TEMP',\n",
        "                  'lws',\n",
        "                  'precipitation',\n",
        "                  'lprec',\n",
        "                  'NE',\n",
        "                  'NW',\n",
        "                  'SW',\n",
        "                  'SE',\n",
        "                  'cv']\n",
        "y_final = np.vstack(y['PM_US Post'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXtHRUb5auwQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb_v_ae-A-20"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y['PM_US Post'], test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywPjx0L1BMiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a6f911-d925-47bd-cbe5-80f7ccbe8ed6"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQKmwvtdBkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7304aace-f727-44b8-8e74-bcedbc17798d"
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 73.92  35.  ]\n",
            " [114.4   55.  ]\n",
            " [ 80.35  11.  ]\n",
            " ...\n",
            " [120.26  81.  ]\n",
            " [ 94.63  77.  ]\n",
            " [ 56.53  57.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50DZZy0UyhLi"
      },
      "source": [
        "### Evaluating the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPagAOKDywV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cd3b8b-ad64-4108-d72e-61cc15360057"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2839919035992807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO4b-p1p13QX"
      },
      "source": [
        "## Training Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPaunP_u1_tP",
        "outputId": "d58c85fa-1ec4-4748-f36d-c05301c61627"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg = PolynomialFeatures(degree = 4)\n",
        "X_poly = poly_reg.fit_transform(X_train)\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_poly, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8QtwM3V2GuR"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jffJtvtj2K3Y",
        "outputId": "6a3c3784-5aa1-4e74-bbd7-93d5a2beba13"
      },
      "source": [
        "y_pred = regressor.predict(poly_reg.transform(X_test))\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 11.78  35.  ]\n",
            " [ 55.39  55.  ]\n",
            " [ 40.96  11.  ]\n",
            " ...\n",
            " [170.77  81.  ]\n",
            " [171.61  77.  ]\n",
            " [ 90.88  57.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkccE5pu2OKy"
      },
      "source": [
        "### Evaluating the Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df2Nc2aa2RBl",
        "outputId": "a2ccd96e-316c-4334-9b9a-c5574bf9b3df"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2261452363395572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8NXs9af4IsR"
      },
      "source": [
        "## Training SVR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU9SaQrl4VvR"
      },
      "source": [
        "First I need to feature scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKbUhOqL4aQ7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "X_train_tran = sc_X.fit_transform(X_train)\n",
        "y_train_tran = sc_y.fit_transform(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3vOZOmB4gOL"
      },
      "source": [
        "Now Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVhpCUoF4g-_",
        "outputId": "b3afff7a-1aaf-4f4a-9d32-5cb43959e6cb"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X_train_tran, y_train_tran)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6XYeWBN4qPO"
      },
      "source": [
        "### Predicting the test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMaUufPV4vij",
        "outputId": "a663edda-2721-405e-bd32-eba603d97dd6"
      },
      "source": [
        "y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)))\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 45.93  35.  ]\n",
            " [ 53.58  55.  ]\n",
            " [ 23.57  11.  ]\n",
            " ...\n",
            " [112.26  81.  ]\n",
            " [132.13  77.  ]\n",
            " [ 79.62  57.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrOEQ-jz4w8a"
      },
      "source": [
        "Evaluating the model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwMs9ZR44yg6",
        "outputId": "f27b5c95-326f-4269-efc1-ad82b5f5e0f5"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5271147748923304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gw28A2X5pTh"
      },
      "source": [
        "## Training Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LATYfAPL6CzE",
        "outputId": "3c9ea666-5949-439d-ac96-ed0da138fe00"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=0, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB3DK7Bn51IR"
      },
      "source": [
        "### Predicting the test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJdGssTK6AN3",
        "outputId": "e12443ab-c82f-49aa-eaf0-84ba59198ddd"
      },
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[49.45 35.  ]\n",
            " [81.74 55.  ]\n",
            " [10.51 11.  ]\n",
            " ...\n",
            " [99.2  81.  ]\n",
            " [89.07 77.  ]\n",
            " [72.68 57.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz6OmhL155nz"
      },
      "source": [
        "### Evaluating the model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPV01hGN6Anw",
        "outputId": "94b90b03-4229-4712-9e12-4b967215d8f0"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8292150375914632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6XX8PIT1c21"
      },
      "source": [
        "## Using the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEQadgtO1g8S"
      },
      "source": [
        "I find that a random forest predicts the PM levels with the best R^2 score. This can then be used in the future to predict the PM levels based on the variety of features. What is left is analysizng the features some more to define a baseline as to what qualifies a \"high PM2.5\" day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH7Vxd6U2tNg"
      },
      "source": [
        "### Analyzing the impact of the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOzIiewW2yZF",
        "outputId": "1c61dec1-a6a2-4d1b-f1c9-7a4de1dc48b6"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/54/04cab6e1c0ae535bec93f795d8403fdf6caf66fa5a6512263202dbb14ea6/eli5-0.11.0-py2.py3-none-any.whl (106kB)\n",
            "\r\u001b[K     |███                             | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v09oQuSO26x7",
        "outputId": "d24e7175-fd80-46a1-c568-cd115cc6ece0"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "#perm = PermutationImportance(regressor, random_state=0).fit(y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1))\n",
        "perm = PermutationImportance(regressor, random_state=0).fit(X_test, y_test.reshape(len(y_test),1))\n",
        "print(eli5.format_as_text(eli5.explain_weights(perm, feature_names=features_final)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained as: feature importances\n",
            "\n",
            "Feature importances, computed as a decrease in score when feature\n",
            "values are permuted (i.e. become noise). This is also known as \n",
            "permutation importance.\n",
            "\n",
            "If feature importances are computed on the same data as used for training, \n",
            "they don't reflect importance of features for generalization. Use a held-out\n",
            "dataset if you want generalization feature importances.\n",
            "\n",
            "1.4283 ± 0.0328  month\n",
            "0.7075 ± 0.0274  season\n",
            "0.6012 ± 0.0108  DEWP\n",
            "0.3918 ± 0.0120  HUMI\n",
            "0.3312 ± 0.0128  day\n",
            "0.2172 ± 0.0093  PRES\n",
            "0.1807 ± 0.0048  year\n",
            "0.1393 ± 0.0112  lws\n",
            "0.0887 ± 0.0057  NW\n",
            "0.0524 ± 0.0067  hour\n",
            "0.0470 ± 0.0030  TEMP\n",
            "0.0157 ± 0.0026  NE\n",
            "0.0042 ± 0.0005  SE\n",
            "0.0021 ± 0.0003  lprec\n",
            "0.0009 ± 0.0003  cv\n",
            "0.0007 ± 0.0002  precipitation\n",
            "     0 ± 0.0000  SW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLL-Ual95zCO"
      },
      "source": [
        "Some interesting take away is that it seems to matter a lot what time of the year it is. Also, the humidity, dew point, and pressure are very important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g03zr-j6Rsn"
      },
      "source": [
        "## Determining a High PM2.5 day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BerdMXoS6Ym3"
      },
      "source": [
        "The definition for a high PM2.5 day is not standardized globally, but well respected standards in the United States and Europe are defined. A daily air density of PM2.5 particles above the thresholds of 35 micrograms/m^3 and 25 micrograms/m^3 represent the standard of high PM2.5 days for the US EPA and European Union respectively. For this study, we will choose the more conservative threshold of 35 micrograms/m^3 to define a high PM2.5 day but our analysis and modelling up until this point is entirely independent of this choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huZVXbK97k-b",
        "outputId": "efc7ee34-6f18-48ae-a87b-ec657ebe9fbd"
      },
      "source": [
        "mu_thres = 35\n",
        "sample_days = [['year',\n",
        "                  'month',\n",
        "                  'day',\n",
        "                  'hour',\n",
        "                  'season',\n",
        "                  'DEWP',\n",
        "                  'HUMI',\n",
        "                  'PRES',\n",
        "                  'TEMP',\n",
        "                  'lws',\n",
        "                  'precipitation',\n",
        "                  'lprec',\n",
        "                  'NE',\n",
        "                  'NW',\n",
        "                  'SW',\n",
        "                  'SE',\n",
        "                  'cv']]\n",
        "sample_days.append([2021,\n",
        "                    7,\n",
        "                    15,\n",
        "                    12,\n",
        "                    2,\n",
        "                    26,\n",
        "                    79,\n",
        "                    1020,\n",
        "                    28,\n",
        "                    2,\n",
        "                    0.,\n",
        "                    0.01,\n",
        "                    1,\n",
        "                    0,\n",
        "                    0,\n",
        "                    1,\n",
        "                    0])\n",
        "print(np.array(sample_days[1]).reshape(1, -1))\n",
        "pred_PM = regressor.predict(np.array(sample_days[1]).reshape(1, -1))\n",
        "\n",
        "if pred_PM > mu_thres:\n",
        "  print(\"I predict this day is a HIGH PM2.5 day,\")\n",
        "else:\n",
        "  print(\"I predict this day is a LOW PM2.5 day,\")\n",
        "print(\"with a PM2.5 value of \" + str(pred_PM[-1]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.02e+03 7.00e+00 1.50e+01 1.20e+01 2.00e+00 2.60e+01 7.90e+01 1.02e+03\n",
            "  2.80e+01 2.00e+00 0.00e+00 1.00e-02 1.00e+00 0.00e+00 0.00e+00 1.00e+00\n",
            "  0.00e+00]]\n",
            "I predict this day is a HIGH PM2.5 day,\n",
            "with a PM2.5 value of 86.92\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}